# BUG-076: Event Cache lacks global memory limit monitoring and enforcement

**Status**: Open  
**Severity**: High  
**Priority**: P1 (High)  
**Component**: State Management / Event Cache  
**Reported Date**: 2025-07-23  
**Reporter**: System Analysis  
**Assignee**: Unassigned  

## Summary
The Event Cache has no global memory limit enforcement across all change groups, risking out-of-memory errors when multiple groups are active simultaneously.

## Description
Each CircularBuffer enforces its own maxEvents limit, but there's no coordination or global memory limit across all buffers. This creates several risks:
- Multiple active change groups can consume unbounded memory
- No way to prioritize important groups when memory is constrained  
- No early warning system before OOM errors
- Memory estimation is rough (200 bytes per event) and not validated
- No adaptive behavior under memory pressure

In a production system with 50+ change groups at 33Hz, memory usage could exceed available resources quickly.

## Steps to Reproduce
1. Create an EventCacheManager
2. Create 50 change groups, each with maxEvents: 100000
3. Start auto-polling all groups at 100ms intervals
4. Add varying numbers of controls to each group
5. Let system run for 1 hour
6. Observe total memory usage approaches system limits
7. No warning or adaptive behavior occurs before OOM

## Expected Behavior
- Global memory limit should be configurable (e.g., 500MB)
- System should track total memory usage across all buffers
- Warning events when approaching limit (80%, 90%)
- Automatic eviction of oldest events when limit exceeded
- Priority system to protect important groups
- Accurate memory usage calculation

## Actual Behavior
- Each buffer operates independently
- No global memory tracking
- No memory pressure handling
- First indication of problem is OOM crash
- Memory estimation may be inaccurate

## Environment
- **OS**: All
- **Node.js Version**: v20.11.0+
- **Project Version/Commit**: Current main branch

## Error Logs/Stack Trace
```
FATAL ERROR: Reached heap limit Allocation failed - JavaScript heap out of memory
```

## Root Cause Analysis
- **File(s)**: src/mcp/state/event-cache/manager.ts
- **Line(s)**: Missing functionality
- **Cause**: Original design didn't account for multiple high-frequency groups

## Proposed Solution
```typescript
export interface EventCacheConfig {
  maxEvents: number;
  maxAgeMs: number;
  globalMemoryLimitMB?: number; // New option
  memoryCheckIntervalMs?: number; // New option
  compressOldEvents?: boolean;
  persistToDisk?: boolean;
}

export class EventCacheManager extends EventEmitter {
  private globalMemoryLimitBytes: number;
  private memoryCheckInterval?: NodeJS.Timeout;
  private lastMemoryPressure: number = 0;
  
  constructor(config: EventCacheConfig) {
    super();
    this.globalMemoryLimitBytes = (config.globalMemoryLimitMB || 500) * 1024 * 1024;
    this.startMemoryMonitoring();
  }
  
  private startMemoryMonitoring(): void {
    if (this.defaultConfig.memoryCheckIntervalMs) {
      this.memoryCheckInterval = setInterval(() => {
        this.checkMemoryPressure();
      }, this.defaultConfig.memoryCheckIntervalMs || 10000);
      
      this.memoryCheckInterval.unref();
    }
  }
  
  private checkMemoryPressure(): void {
    const usage = this.getGlobalMemoryUsage();
    const percentage = (usage / this.globalMemoryLimitBytes) * 100;
    
    // Emit warnings at thresholds
    if (percentage >= 90 && this.lastMemoryPressure < 90) {
      logger.error('Event cache memory critical', { usage, percentage });
      this.emit('memoryPressure', { level: 'critical', percentage });
    } else if (percentage >= 80 && this.lastMemoryPressure < 80) {
      logger.warn('Event cache memory high', { usage, percentage });
      this.emit('memoryPressure', { level: 'high', percentage });
    }
    
    this.lastMemoryPressure = percentage;
    
    // Take action if over limit
    if (usage > this.globalMemoryLimitBytes) {
      this.handleMemoryPressure(usage);
    }
  }
  
  private getGlobalMemoryUsage(): number {
    let total = 0;
    
    for (const [groupId, buffer] of this.buffers) {
      // More accurate memory calculation
      const events = buffer.getSize();
      const avgEventSize = this.calculateAverageEventSize(groupId);
      total += events * avgEventSize;
    }
    
    // Add overhead for indexes and metadata
    total *= 1.2; // 20% overhead estimate
    
    return total;
  }
  
  private calculateAverageEventSize(groupId: string): number {
    // Sample recent events to get accurate size
    const buffer = this.buffers.get(groupId);
    if (!buffer || buffer.isEmpty()) return 200; // Default estimate
    
    const sample = buffer.getNewest();
    if (!sample) return 200;
    
    // Calculate actual size including all fields
    const size = JSON.stringify(sample).length * 2; // UTF-16 in memory
    return Math.max(size, 200); // Minimum 200 bytes
  }
  
  private handleMemoryPressure(currentUsage: number): void {
    logger.warn('Handling memory pressure', { 
      currentUsage, 
      limit: this.globalMemoryLimitBytes 
    });
    
    // Strategy 1: Evict oldest events from largest buffers
    const bufferSizes = Array.from(this.buffers.entries())
      .map(([id, buffer]) => ({
        groupId: id,
        size: buffer.getSize(),
        memory: buffer.getSize() * this.calculateAverageEventSize(id)
      }))
      .sort((a, b) => b.memory - a.memory);
    
    let freed = 0;
    const target = currentUsage - (this.globalMemoryLimitBytes * 0.8); // Free to 80%
    
    for (const { groupId, size } of bufferSizes) {
      if (freed >= target) break;
      
      const buffer = this.buffers.get(groupId)!;
      const toEvict = Math.min(Math.floor(size * 0.1), 1000); // Evict 10% or 1000
      
      // Need new method to force eviction
      const evicted = buffer.forceEvict(toEvict);
      freed += evicted * this.calculateAverageEventSize(groupId);
      
      logger.info('Evicted events due to memory pressure', { 
        groupId, 
        evicted,
        remaining: buffer.getSize()
      });
    }
    
    this.emit('memoryPressureResolved', { freed, currentUsage: currentUsage - freed });
  }
  
  // Add method to set group priorities
  setGroupPriority(groupId: string, priority: 'high' | 'normal' | 'low'): void {
    // Store priorities to protect high-priority groups during eviction
  }
}
```

## Workaround
- Monitor process memory externally
- Restart service when memory is high
- Reduce maxEvents per group
- Limit number of active groups

## Test Cases
- [ ] Unit test: Memory calculation accuracy
- [ ] Unit test: Memory pressure detection at 80% and 90%
- [ ] Unit test: Automatic eviction when over limit
- [ ] Integration test: Multiple groups under memory pressure
- [ ] Performance test: Memory monitoring overhead
- [ ] Stress test: Behavior at memory limit

## Related Issues
- Related to: BUG-073 (Background cleanup timer)
- Related to: BUG-072 (Event Cache implementation)
- Blocks: Production deployment with multiple groups

## Additional Context
- Critical for production stability
- May need different eviction strategies (LRU, priority-based)
- Consider integration with Node.js memory warnings
- Future: Could add disk spillover for evicted events

## Acceptance Criteria
- [ ] Global memory limit is enforced
- [ ] Memory usage is accurately calculated
- [ ] Warning events emitted at 80% and 90%
- [ ] Automatic eviction prevents OOM
- [ ] Memory monitoring has minimal overhead
- [ ] Documentation includes memory planning guide

## Notes
This is essential for production deployment. Without global memory limits, the Event Cache is a reliability risk in systems with many change groups.

---
**Labels**: bug, event-cache, memory-management, high-priority, production-blocker  
**Milestone**: Event Cache GA